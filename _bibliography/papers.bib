---
---

@article{lowegupta-s2p-emnlp,
  title={Seeded self-play for language learning},
  author={Abhinav Gupta* and Ryan Lowe* and Jakob Foerster and Douwe Kiela and Joelle Pineau},
  year={2019},
  journal={The First Workshop Beyond Vision and LANguage: inTEgrating Real-World kNowledge (LANTERN) @ EMNLP-IJCNLP},
}

@article{lowegupta-l2c-icml,
  title={Learning to learn to communicate},
  author={Ryan Lowe* and Abhinav Gupta* and Jakob Foerster and Douwe Kiela and Joelle Pineau},
  year={2019},
  journal={Adaptive & Multitask Learning Workshop (AMTL) @ ICML},
  url={https://openreview.net/forum?id=rkxJrcHo2V}
}

@article{lowegupta-l2c-rldm,
  title={Learning to learn to communicate},
  author={Abhinav Gupta* and Ryan Lowe* and Jakob Foerster and Douwe Kiela and Joelle Pineau},
  year={2019},
  journal={The Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM)},
  extra={Oral Presentation},
  url={https://openreview.net/forum?id=Skgi2oSIdH}
}

@patent{name,
 title={Removing and Replacing Objects in Images According to a Directed User Conversation},
 author={Scott Cohen and Brian Price and Abhinav Gupta},
 year={2019},
 pubnum={U.S. Patent 2019/0196698 A1},
 assignee={Adobe Inc.},
 url={https://patents.google.com/patent/US20190196698A1/en}
 }

@article{DBLP:journals/corr/abs-1712-00725,
  author    = {Laura Graesser and
               Abhinav Gupta and
               Lakshay Sharma and
               Evelina Bakhturina},
  title     = {Sentiment Classification using Images and Label Embeddings},
  journal   = {CoRR},
  volume    = {abs/1712.00725},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.00725},
  archivePrefix = {arXiv},
  eprint    = {1712.00725},
  timestamp = {Mon, 13 Aug 2018 16:49:16 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-00725},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{7953112,
author={Abhinav {Gupta} and Yajie {Miao} and Leonardo {Neves} and Florian {Metze}},
booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Visual features for context-aware speech recognition},
year={2017},
pages={5020-5024},
keywords={feature extraction;learning (artificial intelligence);multimedia computing;speech recognition;ubiquitous computing;video signal processing;word processing;visual feature extraction;context-aware speech recognition;automatic transcriptions;consumer generated multimedia content;word error rates;deep learning;Adaptation models;Videos;Visualization;Acoustics;Feature extraction;Context;Training;audio-visual speech recognition;multimodal processing;deep learning},
doi={10.1109/ICASSP.2017.7953112},
url={https://arxiv.org/abs/1712.00489},
extra={Best Student Paper finalist},
month={March},}
